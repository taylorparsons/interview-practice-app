
# Product Requirements Document (PRD)
# Interview Summary v2 — Per‑Question Insights + Voice Transcript

Project: interview_summary_v2
Owner: Interview Practice App Team
Date Created: 2025-10-09
Status: Draft
Version: 0.1

---

## Executive Summary

Improve the end‑of‑session experience by adding actionable, per‑question insights and full voice transcripts. Today’s summary is generic; candidates need to see what they did well or poorly for each question, why the question was asked, and the full text of what they said in voice mode. The outcome is a focused, coach‑like review that accelerates improvement.

Core Value Proposition:
- Per‑question, actionable feedback instead of generic rollups
- Transparent rationale (“why asked”) to align prep with interviewer intent
- Persisted voice transcripts to review and refine answers

---

## Problem Statement

### Current Pain Points
- Summary is high‑level and not actionable per question
- No explanation of interviewer intent (“why asked”)
- Voice responses aren’t persisted or easy to review
- Candidates can’t compare questions or revisit details later

### Why Now
- Voice interview coaching is available; transcripts/events already surface in the UI
- Users request deeper guidance and clarity per question
- Minimal backend lift: sessions are JSON on disk; UI can be extended incrementally

---

## Success Criteria

### Must Have (MVP)
Functional Requirements:
1. Per‑question cards: question text, score, strengths, improvements, example improvement
2. “Why asked” field per question (intent/competency) generated by LLM
3. Persisted user voice transcript per question and “View full transcript” toggle
4. Backwards compatible with existing sessions (graceful fallbacks)

Non-Functional Requirements:
1. Privacy: keep transcripts local to the session JSON; do not upload beyond evaluation context
2. Performance: summary renders under 200 ms for ≤ 15 questions; transcript fetch < 500 ms local
3. Reliability: tolerate missing fields and partial sessions; no crashes
4. Maintainability: minimal schema changes; additive keys only
5. UX baseline: readable, scannable cards; copy/download transcript affordance

Success Metrics:
- 100% of questions show a card with at least score + strengths + improvements
- ≥ 80% of voice sessions persist a transcript per question
- ≥ 50% reduction in “summary not helpful” feedback in user testing

### Should Have (Phase 2)
- Download transcript per question
- Competency tags (e.g., Leadership, Communication) derived from “why asked”

### Could Have (Phase 3)
- Export summary to PDF
- Side‑by‑side “Original vs Improved” answer diff

### Won’t Have (Out of Scope)
- Multi‑speaker diarization
- Multi‑language support

---

## User Personas & Use Cases

### Primary Persona: Job Seeker
Background:
- Role: Candidate preparing for interviews
- Context: Web browser; voice coaching enabled
- Goals: Improve answers quickly; understand interviewer intent
- Pain: Generic feedback; no access to what they actually said

Key Use Cases
Use Case 1: Review per‑question feedback
```
Scenario: “I finished a mock interview and want to see where to improve.”
Current State: High‑level strengths/improvements only
Desired State:
1. See a card per question
2. Expand to view strengths, improvements, example
3. Read “why asked”
Outcome: Clear, actionable next steps
```

Use Case 2: Read my voice transcript
```
Scenario: “I used voice and want to read exactly what I said.”
Current State: Transcript not persisted in summary
Desired State:
1. Toggle transcript in a card
2. Copy or download it
Outcome: Edit and refine for next practice
```

---

## System Overview

### High-Level Architecture
```
┌──────────────┐   voice events   ┌───────────────────────┐
│  Browser UI  │ ───────────────▶ │  FastAPI (Realtime)   │
└─────┬────────┘                  └─────────┬─────────────┘
      │  GET /sessions, /session, /documents, /voice-transcript
      ▼
┌──────────────────────┐   JSON   ┌─────────────────────────┐
│  Summary UI (cards)  │ ◀──────▶ │  session_store/*.json   │
└──────────────────────┘         └─────────────────────────┘
```

### Core Components
- Per‑Question Evaluator: extends existing evaluation JSON to include `why_asked`
- Transcript Capture: collects user speech by question index and persists
- Summary Renderer: builds cards from questions, per_question, answers, transcripts
- Endpoints: POST transcript; GET documents (added); enriched GET session

---

## Data Requirements

### Session Schema Additions
```json
{
  "voice_transcripts": { "0": "full text", "1": "..." },
  "per_question": [
    {
      "score": 8,
      "strengths": ["clear structure"],
      "weaknesses": ["too long"],
      "feedback": "…",
      "why_asked": "assesses ownership and outcomes",
      "example_improvement": "…"
    }
  ]
}
```

### Data Constraints
- Additive keys only; legacy sessions remain valid
- Retain transcripts with the session until deleted by the user

---

## Technical Constraints

### Platform
- OS/Runtime: Web + Python 3
- Deployment: Local dev; file‑backed persistence
- Storage: JSON files under `app/session_store/`
- Processing: LLM calls (OpenAI) for evaluation

### Technology Stack
Backend:
- Python + FastAPI; file persistence; OpenAI SDK

Frontend:
- Vanilla JS + Tailwind; no framework required

### Performance Targets
- Render summary p95 < 200 ms for ≤ 15 questions
- Transcript POST p95 < 300 ms local

### Storage Targets
- Transcripts: ~1–3 KB per question typical

---

## Dependencies & Integrations

Libraries:
- openai — evaluation + realtime
- httpx — HTTP client
- fastapi/uvicorn — API server

External APIs:
- OpenAI — text/eval; realtime voice (existing)

---

## Security & Privacy

Privacy Requirements:
1. Do not upload full transcripts elsewhere except as part of evaluation context
2. Keep uploads in `app/uploads/` and session JSON in `app/session_store/` (already git‑ignored)
3. Honor `.env` for keys; never log PII

Data Access:
- Read/Write within session scope only

Threats & Controls:
- Leakage via logs → scrub PII from logs; avoid dumping texts at INFO

---

## User Experience Requirements

Design Principles:
1. Actionable and scannable
2. Respect user time (fast, concise)
3. Safe disclosure (transcripts behind toggles)

UI Requirements:
1. Per‑question cards under the overall summary
2. Transcript toggle and copy/download
3. Works on desktop and tablet widths

Sample UX Flows:
- Finish interview → Summary screen → Expand Q cards → Toggle transcript → Copy improvements

---

## Risks & Mitigation

Technical Risks
- Transcript boundaries inaccurate
  - Mitigation: finalize on Next/Summary; allow manual edits later
- LLM output variance
  - Mitigation: strict JSON pattern + fallbacks; validate `why_asked`

User Experience Risks
- Too much content per card
  - Mitigation: collapsible sections, progressive disclosure

---

## Timeline & Milestones

Option A — Aggressive 2-Week Plan
- Week 1: backend transcript endpoint + schema + prompt updates
- Week 2: UI cards, transcript toggles, QA polish
Milestone: v1 shipped behind small toggle

Option B — Phased Plan
- Phase 1 (MVP): transcripts + per‑question cards (score/strengths/improvements) — 1 week
- Phase 2 (Enhancements): why_asked + example improvement + download transcript — 1 week
- Phase 3 (Advanced): competency tags + PDF export — later

---

## Open Questions
- Merge typed and voice answers into a single canonical input? — Status: Unresolved
- Competency tags taxonomy (fixed vs model‑generated)? — Status: Unresolved

---

## Success Measurement

Quantitative Metrics
- Sessions with all per‑question cards rendering: Baseline 0 → Target 95% within 2 weeks
- Questions with a persisted transcript: Baseline 0 → Target 80% within 2 weeks

Qualitative Metrics
- “Summary is helpful” in feedback: Baseline low → Target majority positive

Business Impact
- Higher engagement and retention in practice sessions

---

## Appendix

Reference Documents
- Existing Interview Summary implementation

Related Projects / Prior Art
- Coaching apps with per‑question breakdowns

---

Status: Ready for Review
Next Steps:
1. Approve scope for MVP
2. Implement backend transcript endpoint and schema changes
3. Implement UI per‑question cards and toggles

Document Control:
- Author: Interview Practice App Team
- Reviewers: {{add names}}
- Approval Required: Yes
- Version History: v0.1 (2025-10-09) — Initial draft using template
